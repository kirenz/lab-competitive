[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "To solve this lab, you‚Äôll need:\n\nMySQL, MySQL Workbench and a database called db_ecommerce\nAnaconda\n\nUse MySQL Workbench to create a new database called db_ecommerce\nDROP DATABASE IF EXISTS `db_ecommerce`;\nCREATE DATABASE `db_ecommerce`; \nUSE `db_ecommerce`;"
  },
  {
    "objectID": "resources.html#prerequisites",
    "href": "resources.html#prerequisites",
    "title": "Resources",
    "section": "",
    "text": "To solve this lab, you‚Äôll need:\n\nMySQL, MySQL Workbench and a database called db_ecommerce\nAnaconda\n\nUse MySQL Workbench to create a new database called db_ecommerce\nDROP DATABASE IF EXISTS `db_ecommerce`;\nCREATE DATABASE `db_ecommerce`; \nUSE `db_ecommerce`;"
  },
  {
    "objectID": "resources.html#installation",
    "href": "resources.html#installation",
    "title": "Resources",
    "section": "Installation",
    "text": "Installation\n\nMySQL (select ‚ÄúNo thanks, just start my download‚Äù)\n\nWindows\nMac\n\nMySQL Workbench\nAnaconda"
  },
  {
    "objectID": "resources.html#anaconda-environment",
    "href": "resources.html#anaconda-environment",
    "title": "Resources",
    "section": "Anaconda Environment",
    "text": "Anaconda Environment\nInstall the Anaconda Environment env-mr-pip.yml\n\nüíæ Anaconda Environment"
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab",
    "section": "",
    "text": "In this case study, you will step into the shoes of a market researcher for an e-commerce company. Your task is to conduct a comprehensive competitive analysis.\nYou‚Äôll analyze key competitors and examine customer reviews and social media mentions to gauge public sentiment and identify any areas where your company could potentially gain a competitive advantage.\nThrough this process, you‚Äôll gain practical experience in data collection, quantitative analysis, and critical evaluation skills, which are crucial in strategic decision-making.\nFor this case study, we will create a fictional scenario where we have three major e-commerce competitors: E-Shop A, E-Shop B, and E-Shop C.\nWe‚Äôll use SQL and Python for data analysis and visualization.\nTasks\n\nFirst analysis"
  },
  {
    "objectID": "code/data.html",
    "href": "code/data.html",
    "title": "Data generation",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv\nload_dotenv()   # take environment variables from .env\n\nTrue"
  },
  {
    "objectID": "code/data.html#setup",
    "href": "code/data.html#setup",
    "title": "Data generation",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv\nload_dotenv()   # take environment variables from .env\n\nTrue"
  },
  {
    "objectID": "code/data.html#create-data",
    "href": "code/data.html#create-data",
    "title": "Data generation",
    "section": "Create data",
    "text": "Create data\n\n# Function to generate monthly data\ndef generate_monthly_data(eshop_name, start_year, num_years=3):\n    # Generate a monthly date range for 3 years\n    dates = pd.date_range(start=f'{start_year}-01-01', periods=num_years*12, freq='M')\n    \n    # Initialize a random number generator\n    rng = np.random.default_rng(42)\n\n    # Generate revenues, active user base, ratings, social media followers, and response times\n    revenues = np.round(np.linspace(10, 50, num=num_years*12) + rng.normal(scale=3, size=num_years*12), 2)\n    time_on_site = np.round(np.linspace(1, 10, num=num_years*12) + rng.normal(scale=1, size=num_years*12), 2)\n    ratings = np.clip(np.linspace(3.5, 4.5, num=num_years*12) + rng.normal(scale=0.1, size=num_years*12), 1, 5)\n    social_followers = np.round(np.linspace(100, 1000, num=num_years*12) + rng.normal(scale=50, size=num_years*12), 2)\n    response_times = np.clip(np.linspace(2, 1, num=num_years*12) + rng.normal(scale=0.1, size=num_years*12), 0.5, 2.5)\n\n    # Create a DataFrame\n    data = {\n        'eshop_name': eshop_name,\n        'date': dates,\n        'annual_revenue': revenues,\n        'time_on_site': time_on_site,\n        'average_rating': ratings,\n        'social_media_followers': social_followers,\n        'average_response_time': response_times\n    }\n    df = pd.DataFrame(data)\n    return df\n\n# Generate data for E-ShopA, E-ShopB, and E-ShopC\ndf_a = generate_monthly_data('E-ShopA', start_year=2020)\ndf_b = generate_monthly_data('E-ShopB', start_year=2020)\ndf_c = generate_monthly_data('E-ShopC', start_year=2020)\n\n# Combine the data into one DataFrame\ndf = pd.concat([df_a, df_b, df_c])\n\n# Make numbers different\nLIST = ['annual_revenue', 'time_on_site', 'average_rating', 'social_media_followers', 'average_response_time']\nLEN = len(df)\nDATA = np.random.uniform(0.5, 1.5, size=LEN)\n\nfor i in LIST:\n    df[i] = df[i] * DATA\n\ndf = df.round(2)\n\n# Save data\ndf.to_csv(\"ecommerce.csv\", index=False)\n\n  eshop_name       date  annual_revenue  time_on_site  average_rating  \\\n0    E-ShopA 2020-01-31           13.35          1.09            4.17   \n1    E-ShopA 2020-02-29           10.74          0.56            4.79   \n2    E-ShopA 2020-03-31           11.91          0.57            2.92   \n3    E-ShopA 2020-04-30           16.38          2.44            3.68   \n4    E-ShopA 2020-05-31            6.52          2.07            2.67   \n\n   social_media_followers  average_response_time  \n0                  173.76                   2.35  \n1                   52.69                   2.58  \n2                  141.79                   1.54  \n3                  190.57                   1.92  \n4                  129.49                   1.49"
  },
  {
    "objectID": "code/data.html#sql",
    "href": "code/data.html#sql",
    "title": "Data generation",
    "section": "SQL",
    "text": "SQL\nFirst, create the database in Workbench\n\nengine = create_engine(\"mysql+pymysql://\" + os.environ['DB_URL'] + \"/db_ecommerce\", pool_pre_ping=True, pool_recycle=300)\n\n\n# Use pandas to_sql function to create the table in the database\ndf.to_sql('ecommerce', engine, if_exists='replace')\n\n108"
  },
  {
    "objectID": "code/first-analysis.html",
    "href": "code/first-analysis.html",
    "title": "First analysis",
    "section": "",
    "text": "Solve the following tasks by inserting the SQL queries.\nExample query (we include df_example at the end of the code cell to print the result):"
  },
  {
    "objectID": "code/first-analysis.html#setup",
    "href": "code/first-analysis.html#setup",
    "title": "First analysis",
    "section": "Setup",
    "text": "Setup\n\nimport os\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv"
  },
  {
    "objectID": "code/first-analysis.html#data",
    "href": "code/first-analysis.html#data",
    "title": "First analysis",
    "section": "Data",
    "text": "Data\nConnect to your MySQL-database ‚Äúdb_ecommerce‚Äù (make sure to prepare your .env file)\n\nload_dotenv()   # take environment variables from .env\n\nengine = create_engine(\"mysql+pymysql://\" + os.environ['DB_URL'] + \"/db_ecommerce\", pool_pre_ping=True, pool_recycle=300)\n\n\n# Use pandas to_sql function to create the table in the database\ndf = pd.read_csv('https://raw.githubusercontent.com/kirenz/lab-competitive/main/code/ecommerce.csv')\ndf.to_sql('ecommerce', engine, if_exists='replace')"
  },
  {
    "objectID": "code/first-analysis.html#average-revenue-by-e-shop",
    "href": "code/first-analysis.html#average-revenue-by-e-shop",
    "title": "First analysis",
    "section": "Average Revenue by E-Shop",
    "text": "Average Revenue by E-Shop\n\nShow the average revenue for all shops\nUse the alias average_revenue\n\n\n\ndf_avg_revenue = pd.read_sql(\"\"\"\n    SELECT eshop_name, AVG(annual_revenue) as average_revenue\n    FROM ecommerce_data\n    GROUP BY eshop_name;\n\"\"\", engine)\n\ndf_avg_revenue\n\n\n\n\n\n\n\n\neshop_name\naverage_revenue\n\n\n\n\n0\nE-ShopA\n54.163333\n\n\n1\nE-ShopB\n54.360000\n\n\n2\nE-ShopC\n47.520556"
  },
  {
    "objectID": "code/first-analysis.html#e-shop-with-the-highest-average-rating",
    "href": "code/first-analysis.html#e-shop-with-the-highest-average-rating",
    "title": "First analysis",
    "section": "E-Shop with the Highest Average Rating",
    "text": "E-Shop with the Highest Average Rating\n\nOnly show the E-Shop with the highest average rating\nUse the alias average_rating\n\n\n\ndf_best_rating = pd.read_sql(\"\"\"\n    SELECT eshop_name, AVG(average_rating) as average_rating\n    FROM ecommerce_data\n    GROUP BY eshop_name\n    ORDER BY average_rating DESC\n    LIMIT 1;\n\"\"\", engine)\n\ndf_best_rating\n\n\n\n\n\n\n\n\neshop_name\naverage_rating\n\n\n\n\n0\nE-ShopB\n7.203333"
  },
  {
    "objectID": "code/first-analysis.html#e-shop-performance-over-time",
    "href": "code/first-analysis.html#e-shop-performance-over-time",
    "title": "First analysis",
    "section": "E-Shop Performance Over Time",
    "text": "E-Shop Performance Over Time\n\nShow the annual revenue per E-Shop by year\nUse the aliases year and total_revenue\n\n\n\ndf_revenue_by_year = pd.read_sql(\"\"\"\n    SELECT eshop_name, YEAR(date) as year, SUM(annual_revenue) as total_revenue\n    FROM ecommerce_data\n    GROUP BY eshop_name, year;\n\"\"\", engine)\n\ndf_revenue_by_year\n\n\n\n\n\n\n\n\neshop_name\nyear\ntotal_revenue\n\n\n\n\n0\nE-ShopA\n2020\n355.79\n\n\n1\nE-ShopA\n2021\n608.77\n\n\n2\nE-ShopA\n2022\n985.32\n\n\n3\nE-ShopB\n2020\n359.12\n\n\n4\nE-ShopB\n2021\n660.61\n\n\n5\nE-ShopB\n2022\n937.23\n\n\n6\nE-ShopC\n2020\n279.54\n\n\n7\nE-ShopC\n2021\n600.67\n\n\n8\nE-ShopC\n2022\n830.53"
  },
  {
    "objectID": "code/first-analysis.html#maximum-social-media-followers",
    "href": "code/first-analysis.html#maximum-social-media-followers",
    "title": "First analysis",
    "section": "Maximum Social Media Followers",
    "text": "Maximum Social Media Followers\n\nShow the maximum amount of social media followers for every E-shop in a descending order.\nUse the alias max_followers\n\n\n\ndf_most_followers = pd.read_sql(\"\"\"\n    SELECT eshop_name, MAX(social_media_followers) as max_followers\n    FROM ecommerce_data\n    GROUP BY eshop_name\n    ORDER BY max_followers DESC;\n\"\"\", engine)\n\ndf_most_followers\n\n\n\n\n\n\n\n\neshop_name\nmax_followers\n\n\n\n\n0\nE-ShopA\n2416.26\n\n\n1\nE-ShopC\n2265.09\n\n\n2\nE-ShopB\n2253.55"
  },
  {
    "objectID": "code/first-analysis.html#monthly-time-on-site-overview",
    "href": "code/first-analysis.html#monthly-time-on-site-overview",
    "title": "First analysis",
    "section": "Monthly Time on Site overview",
    "text": "Monthly Time on Site overview\n\nShow a monthly overview of the average time on site for every E-shop (order by E-shop and month)\nUse the aliases month and average_time_on_site\nHint: in Python, you need to use %% instead of % in your query. This means you have to use DATE_FORMAT(date, '%%m')\n\n\ndf_user_growth = pd.read_sql(\"\"\"\n    SELECT eshop_name, DATE_FORMAT(date, '%%m') as month, AVG(time_on_site) as average_time_on_site\n    FROM ecommerce_data\n    GROUP BY eshop_name, month;\n\"\"\", engine)\n\ndf_user_growth\n\n\n\n\n\n\n\n\neshop_name\nmonth\naverage_time_users\n\n\n\n\n0\nE-ShopA\n01\n5.266667\n\n\n1\nE-ShopA\n02\n3.813333\n\n\n2\nE-ShopA\n03\n5.186667\n\n\n3\nE-ShopA\n04\n6.670000\n\n\n4\nE-ShopA\n05\n5.360000\n\n\n5\nE-ShopA\n06\n7.266667\n\n\n6\nE-ShopA\n07\n6.110000\n\n\n7\nE-ShopA\n08\n3.676667\n\n\n8\nE-ShopA\n09\n7.250000\n\n\n9\nE-ShopA\n10\n7.033333\n\n\n10\nE-ShopA\n11\n7.420000\n\n\n11\nE-ShopA\n12\n7.513333\n\n\n12\nE-ShopB\n01\n3.630000\n\n\n13\nE-ShopB\n02\n3.930000\n\n\n14\nE-ShopB\n03\n3.236667\n\n\n15\nE-ShopB\n04\n6.406667\n\n\n16\nE-ShopB\n05\n3.626667\n\n\n17\nE-ShopB\n06\n6.233333\n\n\n18\nE-ShopB\n07\n4.786667\n\n\n19\nE-ShopB\n08\n6.523333\n\n\n20\nE-ShopB\n09\n6.510000\n\n\n21\nE-ShopB\n10\n6.833333\n\n\n22\nE-ShopB\n11\n6.136667\n\n\n23\nE-ShopB\n12\n6.613333\n\n\n24\nE-ShopC\n01\n4.530000\n\n\n25\nE-ShopC\n02\n2.836667\n\n\n26\nE-ShopC\n03\n2.786667\n\n\n27\nE-ShopC\n04\n7.063333\n\n\n28\nE-ShopC\n05\n5.053333\n\n\n29\nE-ShopC\n06\n6.830000\n\n\n30\nE-ShopC\n07\n3.930000\n\n\n31\nE-ShopC\n08\n6.566667\n\n\n32\nE-ShopC\n09\n6.356667\n\n\n33\nE-ShopC\n10\n6.496667\n\n\n34\nE-ShopC\n11\n6.383333\n\n\n35\nE-ShopC\n12\n7.563333"
  },
  {
    "objectID": "code/first-analysis.html#close-the-connection",
    "href": "code/first-analysis.html#close-the-connection",
    "title": "First analysis",
    "section": "Close the connection",
    "text": "Close the connection\n\n# close connection\nengine.dispose()"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Download the Jupyter Notebook from Colab"
  },
  {
    "objectID": "code.html#first-analysis",
    "href": "code.html#first-analysis",
    "title": "Code",
    "section": "",
    "text": "Download the Jupyter Notebook from Colab"
  },
  {
    "objectID": "code/first-analysis-c.html",
    "href": "code/first-analysis-c.html",
    "title": "First analysis",
    "section": "",
    "text": "Solve the following tasks by inserting the SQL queries.\nExample query (we include df_example at the end of the code cell to print the result):"
  },
  {
    "objectID": "code/first-analysis-c.html#setup",
    "href": "code/first-analysis-c.html#setup",
    "title": "First analysis",
    "section": "Setup",
    "text": "Setup\n\nimport os\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv"
  },
  {
    "objectID": "code/first-analysis-c.html#data",
    "href": "code/first-analysis-c.html#data",
    "title": "First analysis",
    "section": "Data",
    "text": "Data\nConnect to your MySQL-database ‚Äúdb_ecommerce‚Äù (make sure to prepare your .env file)\n\nload_dotenv()   # take environment variables from .env\n\nengine = create_engine(\"mysql+pymysql://\" + os.environ['DB_URL'] + \"/db_ecommerce\", pool_pre_ping=True, pool_recycle=300)\n\n\n# Use pandas to_sql function to create the table in the database\ndf = pd.read_csv('https://raw.githubusercontent.com/kirenz/lab-competitive/main/code/ecommerce.csv')\ndf.to_sql('ecommerce', engine, if_exists='replace')"
  },
  {
    "objectID": "code/first-analysis-c.html#average-revenue-by-e-shop",
    "href": "code/first-analysis-c.html#average-revenue-by-e-shop",
    "title": "First analysis",
    "section": "Average Revenue by E-Shop",
    "text": "Average Revenue by E-Shop\n\nShow the average revenue for all shops\nUse the alias average_revenue\n\n\n\ndf_avg_revenue = pd.read_sql(\"\"\"\n\n\"\"\", engine)\n\ndf_avg_revenue"
  },
  {
    "objectID": "code/first-analysis-c.html#e-shop-with-the-highest-average-rating",
    "href": "code/first-analysis-c.html#e-shop-with-the-highest-average-rating",
    "title": "First analysis",
    "section": "E-Shop with the Highest Average Rating",
    "text": "E-Shop with the Highest Average Rating\n\nOnly show the E-Shop with the highest average rating\nUse the alias average_rating\n\n\n\ndf_best_rating = pd.read_sql(\"\"\"\n\n\"\"\", engine)\n\ndf_best_rating"
  },
  {
    "objectID": "code/first-analysis-c.html#e-shop-performance-over-time",
    "href": "code/first-analysis-c.html#e-shop-performance-over-time",
    "title": "First analysis",
    "section": "E-Shop Performance Over Time",
    "text": "E-Shop Performance Over Time\n\nShow the annual revenue per E-Shop by year\nUse the aliases year and total_revenue\n\n\n\ndf_revenue_by_year = pd.read_sql(\"\"\"\n\n\"\"\", engine)\n\ndf_revenue_by_year"
  },
  {
    "objectID": "code/first-analysis-c.html#maximum-social-media-followers",
    "href": "code/first-analysis-c.html#maximum-social-media-followers",
    "title": "First analysis",
    "section": "Maximum Social Media Followers",
    "text": "Maximum Social Media Followers\n\nShow the maximum amount of social media followers for every E-shop in a descending order.\nUse the alias max_followers\n\n\n\ndf_most_followers = pd.read_sql(\"\"\"\n\n\"\"\", engine)\n\ndf_most_followers"
  },
  {
    "objectID": "code/first-analysis-c.html#monthly-time-on-site-overview",
    "href": "code/first-analysis-c.html#monthly-time-on-site-overview",
    "title": "First analysis",
    "section": "Monthly Time on Site overview",
    "text": "Monthly Time on Site overview\n\nShow a monthly overview of the average time on site for every E-shop (order by E-shop and month)\nUse the aliases month and average_time_on_site\nHint: in Python, you need to use %% instead of % in your query. This means you have to use DATE_FORMAT(date, '%%m')\n\n\ndf_user_growth = pd.read_sql(\"\"\"\n\n\"\"\", engine)\n\ndf_user_growth"
  },
  {
    "objectID": "code/first-analysis-c.html#close-the-connection",
    "href": "code/first-analysis-c.html#close-the-connection",
    "title": "First analysis",
    "section": "Close the connection",
    "text": "Close the connection\n\n# close connection\nengine.dispose()"
  },
  {
    "objectID": "case.html",
    "href": "case.html",
    "title": "Competitive analysis E-commerce",
    "section": "",
    "text": "Use SQL queries to analyze your data (use the Jupyter Notebook provided in the code section):\n\nCalculate the average annual revenue for each e-shop.\n\n\n\nFind the e-shop with the highest average rating\n\n\n\nCalculate the total annual revenue for each e-shop, for each year.\n\n\n\nWhat is the E-Shop with the most Social Media Followers?\n\n\n\nShow the growth of the active user base each month for each e-shop:"
  },
  {
    "objectID": "case.html#first-analysis",
    "href": "case.html#first-analysis",
    "title": "Competitive analysis E-commerce",
    "section": "",
    "text": "Use SQL queries to analyze your data (use the Jupyter Notebook provided in the code section):\n\nCalculate the average annual revenue for each e-shop.\n\n\n\nFind the e-shop with the highest average rating\n\n\n\nCalculate the total annual revenue for each e-shop, for each year.\n\n\n\nWhat is the E-Shop with the most Social Media Followers?\n\n\n\nShow the growth of the active user base each month for each e-shop:"
  },
  {
    "objectID": "slides/slides.html#text",
    "href": "slides/slides.html#text",
    "title": "Title",
    "section": "Text",
    "text": "Text\n\na ü§ñ\n\nabc\n\n\n\n\nb\nc1\n\nüìö Required reading: A & B (2023)\nhttps://arxiv.org/pdf/2303.12712.pdf\n\nRussell & Norvig, 2009"
  },
  {
    "objectID": "slides/slides.html#image",
    "href": "slides/slides.html#image",
    "title": "Title",
    "section": "Image",
    "text": "Image"
  },
  {
    "objectID": "slides/slides.html#video",
    "href": "slides/slides.html#video",
    "title": "Title",
    "section": "Video",
    "text": "Video"
  },
  {
    "objectID": "slides/slides.html#a-lot-of-text",
    "href": "slides/slides.html#a-lot-of-text",
    "title": "Title",
    "section": "A lot of text",
    "text": "A lot of text\nSmaller heading"
  },
  {
    "objectID": "slides/slides.html#background-image",
    "href": "slides/slides.html#background-image",
    "title": "Title",
    "section": "Background image",
    "text": "Background image\nabc"
  },
  {
    "objectID": "slides/slides.html#code",
    "href": "slides/slides.html#code",
    "title": "Title",
    "section": "Code",
    "text": "Code\n1print('Hello World')\n2for i in LIST:\n  df[i] = df[i].astype('cat')\n\n1\n\nPrint Hello World, and then,\n\n2\n\ntransform all columns in the LIST element to categorical variables"
  },
  {
    "objectID": "slides/slides.html#end",
    "href": "slides/slides.html#end",
    "title": "Title",
    "section": "End",
    "text": "End\n\n\nJan Kirenz"
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "This is a Quarto slidedeck.\n\nCreate new labs GitHub-Repo\nCreate new branch gh-pages\nChange settings in page: gh-pages and root\nOpen VS Code\nChange Quarto seetings in files\nRender all in terminal: quarto render\nPush to GitHub"
  }
]